# ğŸ“Š INFORME TÃ‰CNICO - TAREA 2
## Procesamiento Digital de ImÃ¡genes: Filtros y ClasificaciÃ³n

---

### ğŸ“‹ INFORMACIÃ“N DEL PROYECTO

**Estudiante:** Emmanuel Bustamante  
**InstituciÃ³n:** Universidad de Antioquia  
**Curso:** Procesamiento Digital de ImÃ¡genes  
**Tarea:** Tarea 2 - Filtros y Descriptores de CaracterÃ­sticas  
**Fecha:** Noviembre 2025  
**Plataforma:** [Streamlit Cloud](https://clasificaci-n-de-imagenes-6je33ygv8xeoekkn2dl8qd.streamlit.app/)  
**Repositorio:** [GitHub - Emma-Ok/Clasificaci-n-de-imagenes](https://github.com/Emma-Ok/Clasificaci-n-de-imagenes)

---

## ğŸ“Œ RESUMEN EJECUTIVO

Este proyecto implementa una aplicaciÃ³n web interactiva para procesamiento de imÃ¡genes que abarca dos componentes principales:

1. **PARTE 1 (30%)**: Sistema de aplicaciÃ³n de filtros digitales con visualizaciÃ³n en tiempo real
2. **PARTE 2 (70%)**: Sistema completo de clasificaciÃ³n de caracteres alfanumÃ©ricos usando descriptores de caracterÃ­sticas y aprendizaje automÃ¡tico

La aplicaciÃ³n fue desarrollada en Python usando Streamlit como framework de interfaz grÃ¡fica, OpenCV para procesamiento de imÃ¡genes, scikit-learn para modelos tradicionales de ML, y PyTorch para redes neuronales convolucionales.

**CaracterÃ­sticas principales:**
- Interfaz web interactiva accesible desde cualquier navegador
- 8 filtros digitales implementados con parÃ¡metros ajustables
- 3 modelos de clasificaciÃ³n entrenables (SVM+HOG, SVM+LBP, CNN)
- Dataset de 1,080 imÃ¡genes (36 clases: 0-9, A-Z)
- MÃ©tricas de evaluaciÃ³n completas (accuracy, precision, recall, F1, matriz de confusiÃ³n)
- Despliegue en la nube con Streamlit Cloud

---

## ğŸ¯ OBJETIVOS

### Objetivos Generales
1. Implementar y analizar filtros de procesamiento de imÃ¡genes en el dominio espacial
2. Desarrollar un sistema de clasificaciÃ³n automÃ¡tica de caracteres usando descriptores de caracterÃ­sticas
3. Comparar el desempeÃ±o de mÃ©todos tradicionales (SVM) vs. aprendizaje profundo (CNN)

### Objetivos EspecÃ­ficos
- Programar 8 filtros digitales con parÃ¡metros configurables
- Extraer descriptores HOG y LBP de imÃ¡genes
- Entrenar clasificadores SVM con diferentes descriptores
- Implementar y entrenar una red neuronal convolucional
- Evaluar y comparar los modelos mediante mÃ©tricas estÃ¡ndar
- Crear una interfaz grÃ¡fica intuitiva para demostraciÃ³n

---

## ğŸ› ï¸ METODOLOGÃA

### 1. Fundamentos TeÃ³ricos

El procesamiento digital de imÃ¡genes se basa en dos pilares fundamentales:

**1.1 Procesamiento en el Dominio Espacial**  
Operaciones que se aplican directamente sobre los pÃ­xeles de la imagen. Los filtros espaciales modifican los valores de intensidad mediante operaciones matemÃ¡ticas sobre vecindades locales.

**1.2 AnÃ¡lisis y ExtracciÃ³n de CaracterÃ­sticas**  
TransformaciÃ³n de la informaciÃ³n visual en representaciones numÃ©ricas que capturan propiedades relevantes de la imagen (forma, textura, bordes).

### 2. Enfoque Experimental

El proyecto aborda dos problemas fundamentales del procesamiento de imÃ¡genes:

**PARTE 1 - Filtrado Espacial (30%)**
- ImplementaciÃ³n de 8 filtros clÃ¡sicos
- AnÃ¡lisis comparativo de efectos
- Estudio de parÃ¡metros Ã³ptimos

**PARTE 2 - ClasificaciÃ³n de Patrones (70%)**
- ExtracciÃ³n de descriptores de caracterÃ­sticas
- Entrenamiento de modelos supervisados
- EvaluaciÃ³n cuantitativa del desempeÃ±o

### 3. Dataset

**Estructura:**
- **Total:** 1,080 imÃ¡genes
- **Clases:** 36 (dÃ­gitos 0-9 + letras A-Z)
- **ResoluciÃ³n:** 128Ã—64 pÃ­xeles
- **DivisiÃ³n:**
  - Entrenamiento: 864 imÃ¡genes (80%)
  - ValidaciÃ³n: 216 imÃ¡genes (20%)
- **Formato:** RGB, normalizado a escala de grises para descriptores

**OrganizaciÃ³n de carpetas:**
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class_0/ (24 imÃ¡genes)
â”‚   â”œâ”€â”€ class_1/ (24 imÃ¡genes)
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ class_Z/ (24 imÃ¡genes)
â””â”€â”€ val/
    â”œâ”€â”€ class_0/ (6 imÃ¡genes)
    â”œâ”€â”€ class_1/ (6 imÃ¡genes)
    â”œâ”€â”€ ...
    â””â”€â”€ class_Z/ (6 imÃ¡genes)
```

---

## ğŸ“ PARTE 1: FILTROS DE IMÃGENES (30%)

### 1.1 Filtros Implementados

Se implementaron 8 filtros digitales en el dominio espacial:

#### ğŸ”¹ 1. Filtro de Media
- **PropÃ³sito:** Suavizado mediante promedio aritmÃ©tico
- **FÃ³rmula:** `g(x,y) = (1/mn) Ã— Î£ Î£ f(x+i, y+j)`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7, 9Ã—9)
- **AplicaciÃ³n:** ReducciÃ³n de ruido gaussiano
- **Ventaja:** Simple y eficiente computacionalmente
- **Desventaja:** Difumina bordes

#### ğŸ”¹ 2. Filtro de Mediana
- **PropÃ³sito:** Suavizado mediante valor mediano
- **FÃ³rmula:** `g(x,y) = mediana{f(x+i, y+j)}`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7)
- **AplicaciÃ³n:** Excelente para ruido sal y pimienta
- **Ventaja:** Preserva bordes mejor que la media
- **Desventaja:** Mayor costo computacional

#### ğŸ”¹ 3. Filtro LogarÃ­tmico
- **PropÃ³sito:** CompresiÃ³n de rango dinÃ¡mico
- **FÃ³rmula:** `g(x,y) = c Ã— log(1 + f(x,y))`
- **ParÃ¡metro ajustable:** Factor de escala c (1-100)
- **AplicaciÃ³n:** Realce de detalles en zonas oscuras
- **Ventaja:** Mejora visualizaciÃ³n de imÃ¡genes HDR
- **Desventaja:** Puede sobreexponer zonas claras

#### ğŸ”¹ 4. Filtro Cuadro Normalizado
- **PropÃ³sito:** Suavizado uniforme con normalizaciÃ³n
- **ImplementaciÃ³n:** `cv2.boxFilter()` con `normalize=True`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7, 9Ã—9)
- **AplicaciÃ³n:** ReducciÃ³n de ruido con efecto de blur uniforme
- **Ventaja:** RÃ¡pido y predecible
- **Desventaja:** PÃ©rdida de detalles finos

#### ğŸ”¹ 5. Filtro Gaussiano
- **PropÃ³sito:** Suavizado ponderado gaussianamente
- **FÃ³rmula:** `G(x,y) = (1/2Ï€ÏƒÂ²) Ã— exp(-(xÂ²+yÂ²)/2ÏƒÂ²)`
- **ParÃ¡metros ajustables:** 
  - TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7, 9Ã—9)
  - Sigma Ïƒ (0.5 - 5.0)
- **AplicaciÃ³n:** Preprocesamiento para detecciÃ³n de bordes
- **Ventaja:** Suavizado natural, preserva mejor los bordes que la media
- **Desventaja:** MÃ¡s costoso que filtro de media

#### ğŸ”¹ 6. Filtro Laplaciano
- **PropÃ³sito:** DetecciÃ³n de bordes mediante segunda derivada
- **FÃ³rmula:** `âˆ‡Â²f = âˆ‚Â²f/âˆ‚xÂ² + âˆ‚Â²f/âˆ‚yÂ²`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (1, 3, 5)
- **AplicaciÃ³n:** Realce de bordes y detalles
- **Ventaja:** Detecta bordes en todas direcciones
- **Desventaja:** Muy sensible al ruido

#### ğŸ”¹ 7. Filtro Sobel
- **PropÃ³sito:** DetecciÃ³n de bordes mediante gradiente
- **FÃ³rmulas:**
  - Gx (horizontal): `[-1 0 1; -2 0 2; -1 0 1]`
  - Gy (vertical): `[-1 -2 -1; 0 0 0; 1 2 1]`
  - Magnitud: `G = âˆš(GxÂ² + GyÂ²)`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3, 5, 7)
- **AplicaciÃ³n:** DetecciÃ³n direccional de bordes
- **Ventaja:** Robustez al ruido, detecciÃ³n direccional
- **Desventaja:** Puede perderse informaciÃ³n de bordes dÃ©biles

#### ğŸ”¹ 8. Filtro Canny
- **PropÃ³sito:** DetecciÃ³n Ã³ptima de bordes multi-etapa
- **Etapas:**
  1. Suavizado gaussiano (reducciÃ³n de ruido)
  2. CÃ¡lculo de gradiente (Sobel)
  3. SupresiÃ³n no-mÃ¡xima (adelgazamiento)
  4. UmbralizaciÃ³n con histÃ©resis
- **ParÃ¡metros ajustables:**
  - Umbral inferior (50-200)
  - Umbral superior (100-300)
- **AplicaciÃ³n:** DetecciÃ³n precisa de contornos
- **Ventaja:** Mejor relaciÃ³n seÃ±al-ruido, bordes continuos
- **Desventaja:** Requiere ajuste cuidadoso de umbrales

### 1.2 Fundamento MatemÃ¡tico de Filtros

Los filtros espaciales se pueden clasificar en dos categorÃ­as principales:

**Filtros de Suavizado (Pasa-Bajas)**
- Reducen variaciones abruptas de intensidad
- Aplicaciones: reducciÃ³n de ruido, preprocesamiento
- Trade-off: pÃ©rdida de detalles vs. reducciÃ³n de ruido

**Filtros de Realce (Pasa-Altas)**
- Enfatizan transiciones rÃ¡pidas de intensidad
- Aplicaciones: detecciÃ³n de bordes, sharpening
- Trade-off: sensibilidad al ruido vs. detecciÃ³n de detalles

**OperaciÃ³n de ConvoluciÃ³n**  
Base matemÃ¡tica de los filtros lineales:

```
g(x,y) = Î£ Î£ f(x+i, y+j) Ã— h(i,j)
```

Donde:
- `f(x,y)`: imagen original
- `h(i,j)`: kernel del filtro
- `g(x,y)`: imagen resultante

### 1.3 AnÃ¡lisis Comparativo de Filtros

**SelecciÃ³n segÃºn tipo de ruido:**
- **Ruido gaussiano** â†’ Filtro de Media o Gaussiano
- **Ruido sal y pimienta** â†’ Filtro de Mediana
- **Ruido en imÃ¡genes HDR** â†’ Filtro LogarÃ­tmico

**SelecciÃ³n segÃºn aplicaciÃ³n:**
- **Preprocesamiento general** â†’ Gaussiano
- **DetecciÃ³n de bordes** â†’ Sobel, Canny
- **Realce de detalles** â†’ Laplaciano

---

## ğŸ§  PARTE 2: DESCRIPTORES Y CLASIFICACIÃ“N (70%)

### 2.1 Descriptores de CaracterÃ­sticas

#### ğŸ”¸ HOG (Histogram of Oriented Gradients)

**Fundamento TeÃ³rico:**  
El descriptor HOG se basa en el principio de que la forma y apariencia de objetos locales pueden ser caracterizadas por la distribuciÃ³n de gradientes de intensidad o direcciones de bordes, incluso sin conocimiento preciso de las ubicaciones de los bordes.

**Base MatemÃ¡tica:**

1. **CÃ¡lculo del Gradiente:**
   ```
   Gx = I(x+1,y) - I(x-1,y)
   Gy = I(x,y+1) - I(x,y-1)
   Magnitud: G = âˆš(GxÂ² + GyÂ²)
   OrientaciÃ³n: Î¸ = arctan(Gy/Gx)
   ```

2. **Histograma de Orientaciones:**
   - DivisiÃ³n del espacio angular (0Â°-180Â°) en 9 bins
   - Cada gradiente vota en bins segÃºn su orientaciÃ³n
   - Peso del voto proporcional a la magnitud

3. **NormalizaciÃ³n por Bloques:**
   - Agrupa celdas en bloques de 2Ã—2
   - NormalizaciÃ³n L2-Hys para robustez a iluminaciÃ³n
   ```
   v_norm = v / âˆš(||v||Â² + ÎµÂ²)
   ```

**Propiedades Fundamentales:**
- **Invariancia a iluminaciÃ³n:** NormalizaciÃ³n por bloques
- **Invariancia a traslaciÃ³n:** Uso de gradientes locales
- **Sensibilidad a forma:** Captura estructura geomÃ©trica

**Ventajas:**
- Robusto a cambios de iluminaciÃ³n
- Invariante a pequeÃ±as deformaciones
- Captura informaciÃ³n de forma/estructura

**Desventajas:**
- Sensible a rotaciÃ³n
- No captura informaciÃ³n de textura fina

#### ğŸ”¸ LBP (Local Binary Patterns)

**Fundamento TeÃ³rico:**  
LBP es un operador de textura que caracteriza la estructura espacial de texturas locales mediante comparaciones binarias entre un pÃ­xel central y su vecindad circular.

**Base MatemÃ¡tica:**

1. **CodificaciÃ³n Binaria:**
   ```
   LBP(xc,yc) = Î£(i=0 to P-1) s(gi - gc) Ã— 2^i
   
   donde:
   s(x) = 1 si x â‰¥ 0
   s(x) = 0 si x < 0
   ```

2. **Muestreo Circular:**
   - P puntos en cÃ­rculo de radio R
   - Coordenadas: `(xc + RÃ—cos(2Ï€i/P), yc + RÃ—sin(2Ï€i/P))`
   - InterpolaciÃ³n bilineal para posiciones no enteras

3. **Patrones Uniformes:**
   - PatrÃ³n uniforme: mÃ¡ximo 2 transiciones 0â†’1 o 1â†’0
   - Reduce dimensionalidad: 256 patrones â†’ 59 uniformes
   - Captura ~90% de texturas naturales

**Propiedades Fundamentales:**
- **Invariancia monotÃ³nica:** Robusto a cambios de iluminaciÃ³n
- **Invariancia rotacional:** VersiÃ³n extendida (LBP^riu2)
- **Eficiencia computacional:** Operaciones binarias simples

**Ventajas:**
- Invariante a cambios monÃ³tonos de iluminaciÃ³n
- Muy eficiente computacionalmente
- Captura informaciÃ³n de textura local

**Desventajas:**
- Sensible a ruido
- Pierde informaciÃ³n de contraste

### 2.2 Modelos de ClasificaciÃ³n

Se implementaron 3 modelos diferentes para comparaciÃ³n:

#### ğŸ¤– Modelo 1: SVM + HOG

**Fundamento TeÃ³rico:**  
Las MÃ¡quinas de Vectores de Soporte (SVM) son clasificadores que buscan el hiperplano Ã³ptimo que maximiza el margen entre clases en un espacio de alta dimensionalidad.

**FormulaciÃ³n MatemÃ¡tica:**

**Problema de optimizaciÃ³n:**
```
minimizar: Â½||w||Â² + C Î£ Î¾i
sujeto a: yi(wÂ·xi + b) â‰¥ 1 - Î¾i
```

Donde:
- `w`: vector normal al hiperplano
- `b`: tÃ©rmino de sesgo
- `C`: parÃ¡metro de regularizaciÃ³n
- `Î¾i`: variables de holgura (slack)

**FunciÃ³n de decisiÃ³n:**
```
f(x) = sign(wÂ·x + b)
```

**CaracterÃ­sticas del enfoque SVM+HOG:**
- **Espacio de caracterÃ­sticas:** ~3,780 dimensiones (HOG)
- **Kernel lineal:** Eficiente en alta dimensionalidad
- **NormalizaciÃ³n:** Z-score para escala uniforme
- **Pesos balanceados:** Compensa desbalance de clases

#### ğŸ¤– Modelo 2: SVM + LBP

**Fundamento TeÃ³rico:**  
Este modelo combina la capacidad de LBP para capturar micro-texturas con la robustez del clasificador SVM.

**Diferencias con SVM+HOG:**

**Espacio de caracterÃ­sticas:**
- **Dimensionalidad:** 26 vs. 3,780 (HOG)
- **Tipo de informaciÃ³n:** Textura vs. Forma
- **Complejidad:** Baja vs. Alta

**Ventajas del espacio reducido:**
- Convergencia mÃ¡s rÃ¡pida
- Menor riesgo de overfitting
- Eficiencia computacional

**Trade-offs:**
- â¬†ï¸ Velocidad de entrenamiento
- â¬‡ï¸ Capacidad de representaciÃ³n
- â¬‡ï¸ PrecisiÃ³n en patrones complejos

#### ğŸ¤– Modelo 3: CNN (Convolutional Neural Network)

**Fundamento TeÃ³rico:**  
Las Redes Neuronales Convolucionales aprenden jerarquÃ­as de caracterÃ­sticas directamente de los datos, desde bordes simples hasta patrones complejos.

**Principios Fundamentales:**

**1. OperaciÃ³n de ConvoluciÃ³n:**
```
S(i,j) = (I * K)(i,j) = Î£ Î£ I(m,n)K(i-m, j-n)
                        m  n
```

**2. Campos Receptivos:**
- Cada neurona "ve" una regiÃ³n local de la entrada
- Campos receptivos crecen con la profundidad
- Captura patrones de complejidad creciente

**3. Arquitectura JerÃ¡rquica:**

**Nivel 1 (Baja complejidad):**
- Detectores de bordes (horizontal, vertical, diagonal)
- Filtros Gabor aprendidos
- Patrones locales simples

**Nivel 2 (Media complejidad):**
- Combinaciones de bordes
- Formas bÃ¡sicas (curvas, esquinas)
- Texturas simples

**Nivel 3 (Alta complejidad):**
- Partes de objetos
- Patrones recurrentes
- CaracterÃ­sticas discriminativas

**Nivel 4 (Muy alta complejidad):**
- Representaciones globales
- CaracterÃ­sticas de clase
- Patrones abstractos

**4. Componentes Clave:**

**ConvoluciÃ³n:**
- ExtracciÃ³n de caracterÃ­sticas locales
- Compartir pesos reduce parÃ¡metros
- Invariancia a traslaciÃ³n

**Pooling:**
- ReducciÃ³n de dimensionalidad espacial
- Invariancia a pequeÃ±as deformaciones
- Reduce overfitting

**Batch Normalization:**
- Estabiliza el entrenamiento
- Permite learning rates mayores
- RegularizaciÃ³n implÃ­cita

**Dropout:**
- RegularizaciÃ³n explÃ­cita
- Previene co-adaptaciÃ³n de neuronas
- Simula ensemble de redes

**5. FunciÃ³n de PÃ©rdida:**

**Cross-Entropy multi-clase:**
```
L = -Î£ yi Ã— log(Å·i)
     i

donde:
yi: etiqueta verdadera (one-hot)
Å·i: probabilidad predicha (softmax)
```

**6. OptimizaciÃ³n:**

**Adam Optimizer:**
- Combina momentum + RMSprop
- Tasas de aprendizaje adaptativas
- Convergencia rÃ¡pida y estable

### 2.3 MÃ©tricas de EvaluaciÃ³n

Para cada modelo se calculan las siguientes mÃ©tricas:

#### ğŸ“Š MÃ©tricas Globales
- **Accuracy:** Porcentaje de predicciones correctas
  ```
  Accuracy = (TP + TN) / (TP + TN + FP + FN)
  ```

- **Precision (macro-avg):** Promedio de precisiÃ³n por clase
  ```
  Precision = TP / (TP + FP)
  ```

- **Recall (macro-avg):** Promedio de sensibilidad por clase
  ```
  Recall = TP / (TP + FN)
  ```

- **F1-Score (macro-avg):** Media armÃ³nica de precision y recall
  ```
  F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
  ```

#### ğŸ“Š Matriz de ConfusiÃ³n
- VisualizaciÃ³n 36Ã—36 de predicciones vs. verdad
- Diagonal: Predicciones correctas
- Fuera de diagonal: Confusiones entre clases

#### ğŸ“Š Reporte por Clase
- Precision, Recall, F1-Score para cada una de las 36 clases
- IdentificaciÃ³n de clases problemÃ¡ticas

---

## ğŸ’» MARCO TEÃ“RICO DEL PROCESAMIENTO

### 3.1 TeorÃ­a de SeÃ±ales e ImÃ¡genes

**RepresentaciÃ³n Digital:**
Una imagen digital es una funciÃ³n bidimensional `f(x,y)` donde:
- `x, y`: coordenadas espaciales discretas
- `f`: intensidad o nivel de gris en ese punto

**Teorema de Muestreo (Nyquist-Shannon):**
```
fs â‰¥ 2 Ã— fmax
```
La frecuencia de muestreo debe ser al menos el doble de la frecuencia mÃ¡xima para evitar aliasing.

### 3.2 Espacios de Color

**RGB (Red, Green, Blue):**
- Modelo aditivo basado en percepciÃ³n humana
- Cada pÃ­xel: (R, G, B) âˆˆ [0, 255]Â³

**Escala de Grises:**
```
Gray = 0.299Ã—R + 0.587Ã—G + 0.114Ã—B
```
PonderaciÃ³n basada en sensibilidad del ojo humano.

### 3.3 Transformaciones Fundamentales

**1. Transformaciones Puntuales:**
Operan pÃ­xel por pÃ­xel independientemente:
```
g(x,y) = T[f(x,y)]
```

**2. Transformaciones Locales:**
Usan vecindades (convoluciÃ³n):
```
g(x,y) = Î£ Î£ f(x+i,y+j) Ã— h(i,j)
         i j
```

**3. Transformaciones Globales:**
Consideran toda la imagen (FFT, histograma)

---

## ğŸ“ˆ RESULTADOS

### 4.1 DesempeÃ±o de Modelos

Los resultados esperados (basados en arquitectura y dataset):

| Modelo | Accuracy Esperada | Tiempo Entrenamiento | TamaÃ±o Modelo |
|--------|-------------------|---------------------|---------------|
| **SVM + HOG** | 85-92% | 2-5 min | ~15 MB |
| **SVM + LBP** | 70-80% | <1 min | ~1 MB |
| **CNN** | 90-96% | 10-15 min | ~300 KB |

**AnÃ¡lisis comparativo:**

**SVM + HOG:**
- âœ… Buen balance entre precisiÃ³n y velocidad
- âœ… Interpetable (vectores de soporte)
- âœ… Funciona bien con datos limitados
- âŒ Requiere ingenierÃ­a de caracterÃ­sticas manual
- âŒ Escalado lineal con tamaÃ±o de dataset

**SVM + LBP:**
- âœ… Muy rÃ¡pido (26 caracterÃ­sticas)
- âœ… Eficiente en memoria
- âœ… Bueno para texturas
- âŒ Menor precisiÃ³n que HOG
- âŒ Pierde informaciÃ³n espacial global

**CNN:**
- âœ… Mayor precisiÃ³n potencial
- âœ… Aprendizaje automÃ¡tico de caracterÃ­sticas
- âœ… Escalable a datasets grandes
- âŒ Requiere mÃ¡s datos de entrenamiento
- âŒ Mayor tiempo de entrenamiento
- âŒ Menos interpretable

### 4.2 Despliegue en ProducciÃ³n

**URL de la aplicaciÃ³n:**  
https://clasificaci-n-de-imagenes-6je33ygv8xeoekkn2dl8qd.streamlit.app/

**ConfiguraciÃ³n de despliegue:**

**packages.txt** (dependencias del sistema):
```bash
libgl1-mesa-glx    # OpenGL para OpenCV
libglib2.0-0       # GLib para procesamiento
```

**requirements.txt** (dependencias de Python):
```
opencv-python-headless==4.10.0.84
numpy==1.26.4
matplotlib==3.9.2
scikit-image==0.24.0
Pillow==10.4.0
scikit-learn==1.5.2
torch==2.4.1
torchvision==0.19.1
pandas==2.2.3
seaborn==0.13.2
streamlit==1.39.0
tqdm==4.66.5
```

**Problemas resueltos durante deployment:**
1. âŒ Python 3.13 incompatible con PyTorch â†’ âœ… Forzar Python 3.12
2. âŒ opencv-python requiere libGL â†’ âœ… Usar opencv-python-headless
3. âŒ width='stretch' deprecado â†’ âœ… use_column_width=True
4. âŒ uv instalando versiones incorrectas â†’ âœ… Remover runtime.txt

---

## ğŸ“ CONCLUSIONES

### 5.1 Logros del Proyecto

1. **ImplementaciÃ³n Completa:**
   - âœ… 8 filtros digitales funcionales con parÃ¡metros ajustables
   - âœ… 2 descriptores de caracterÃ­sticas (HOG, LBP) implementados
   - âœ… 3 modelos de clasificaciÃ³n entrenables (SVMÃ—2, CNN)
   - âœ… Interfaz web interactiva y responsive
   - âœ… Despliegue exitoso en Streamlit Cloud

2. **Aprendizajes TÃ©cnicos:**
   - ComprensiÃ³n profunda de filtros en dominio espacial
   - Dominio de descriptores de caracterÃ­sticas tradicionales
   - Experiencia prÃ¡ctica con SVM y redes neuronales
   - Desarrollo de aplicaciones web con Streamlit
   - GestiÃ³n de deployment y dependencias en la nube

3. **Resultados AcadÃ©micos:**
   - DocumentaciÃ³n exhaustiva con fundamentos matemÃ¡ticos
   - ImplementaciÃ³n modular y bien estructurada
   - CÃ³digo reproducible y versionado en Git
   - AplicaciÃ³n funcional accesible pÃºblicamente

### 5.2 AnÃ¡lisis TeÃ³rico Comparativo

**Paradigmas de Aprendizaje:**

**Enfoque Tradicional (Descriptores Manuales + SVM):**

**Ventajas teÃ³ricas:**
- **Base matemÃ¡tica sÃ³lida:** HOG y LBP tienen interpretaciÃ³n geomÃ©trica clara
- **GarantÃ­as teÃ³ricas:** SVM maximiza margen con fundamento estadÃ­stico
- **Eficiencia en datos:** Funciona con datasets limitados (teorÃ­a VC)
- **Interpretabilidad:** Vectores de soporte son ejemplares representativos

**Limitaciones teÃ³ricas:**
- **Sesgo inductivo fijo:** CaracterÃ­sticas diseÃ±adas a priori
- **PÃ©rdida de informaciÃ³n:** CompresiÃ³n manual puede descartar patrones relevantes
- **Escalabilidad:** Complejidad O(nÂ²) en SVM estÃ¡ndar

**Enfoque Moderno (Deep Learning - CNN):**

**Ventajas teÃ³ricas:**
- **Teorema de aproximaciÃ³n universal:** Puede aproximar cualquier funciÃ³n continua
- **Aprendizaje jerÃ¡rquico:** Descubre representaciones Ã³ptimas automÃ¡ticamente
- **Invariancia aprendida:** Adquiere invariancias relevantes del problema
- **Composicionalidad:** Combina caracterÃ­sticas simples en complejas

**Limitaciones teÃ³ricas:**
- **Caja negra:** DifÃ­cil interpretaciÃ³n de caracterÃ­sticas aprendidas
- **MÃ­nimos locales:** OptimizaciÃ³n no convexa
- **Requisitos de datos:** Necesita ejemplos suficientes para generalizar
- **Overfitting:** Alto riesgo con modelos sobreparametrizados

**TeorÃ­a del Aprendizaje EstadÃ­stico:**

Ambos enfoques buscan minimizar el riesgo esperado:
```
R(f) = E[L(Y, f(X))]
```

Pero difieren en cÃ³mo:
- **SVM:** Minimiza riesgo estructural (margen + error)
- **CNN:** Minimiza riesgo empÃ­rico con regularizaciÃ³n

### 5.3 Limitaciones y Trabajo Futuro

**Limitaciones actuales:**
- Dataset limitado (1,080 imÃ¡genes)
- Entrenamiento solo en CPU (no GPU en Streamlit Cloud)
- Sin data augmentation extensiva
- Modelos no optimizados para producciÃ³n (sin cuantizaciÃ³n)

**Mejoras propuestas:**
1. **Dataset:**
   - Aumentar a 10,000+ imÃ¡genes
   - Data augmentation (rotaciÃ³n, escalado, ruido)
   - Incluir imÃ¡genes de diferentes fuentes

2. **Modelos:**
   - Transfer learning (ResNet, EfficientNet pre-entrenados)
   - Ensemble de modelos (voting)
   - OptimizaciÃ³n de hiperparÃ¡metros (Grid Search, Bayesian Opt)
   - CuantizaciÃ³n post-entrenamiento para inferencia rÃ¡pida

3. **AplicaciÃ³n:**
   - API REST para integraciÃ³n
   - Modo batch para procesamiento masivo
   - CachÃ© de modelos para reducir latencia
   - Soporte para GPU en deployment

4. **Filtros:**
   - MÃ¡s filtros (bilateral, anisotropic diffusion)
   - Filtros en dominio de frecuencia (FFT, DCT)
   - Procesamiento en color (espacios HSV, LAB)

### 5.4 ReflexiÃ³n Personal

Este proyecto demostrÃ³ la importancia de entender tanto los fundamentos teÃ³ricos (filtros digitales, descriptores de caracterÃ­sticas) como las herramientas modernas (deep learning, cloud deployment). La implementaciÃ³n prÃ¡ctica revelÃ³ que:

- **No existe un modelo perfecto:** Cada enfoque tiene trade-offs
- **La ingenierÃ­a de datos es crucial:** Preprocesamiento y extracciÃ³n de caracterÃ­sticas impactan significativamente
- **La visualizaciÃ³n es poderosa:** Una interfaz intuitiva facilita la comprensiÃ³n
- **El deployment tiene desafÃ­os Ãºnicos:** Compatibilidad de dependencias, limitaciones de recursos

La experiencia de llevar un proyecto desde la teorÃ­a hasta una aplicaciÃ³n web funcional proporciona una visiÃ³n integral del ciclo de vida del desarrollo de software en machine learning.

---

## ğŸ“š REFERENCIAS

### TeorÃ­a de Filtros
1. Gonzalez, R. C., & Woods, R. E. (2018). *Digital Image Processing* (4th ed.). Pearson.
2. Pratt, W. K. (2007). *Digital Image Processing* (4th ed.). Wiley-Interscience.

### Descriptores de CaracterÃ­sticas
3. Dalal, N., & Triggs, B. (2005). Histograms of oriented gradients for human detection. *CVPR*.
4. Ojala, T., PietikÃ¤inen, M., & MÃ¤enpÃ¤Ã¤, T. (2002). Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. *TPAMI*, 24(7), 971-987.

### Machine Learning
5. Cortes, C., & Vapnik, V. (1995). Support-vector networks. *Machine Learning*, 20(3), 273-297.
6. LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. *Nature*, 521(7553), 436-444.

### Herramientas
7. Bradski, G. (2000). The OpenCV Library. *Dr. Dobb's Journal*.
8. Pedregosa et al. (2011). Scikit-learn: Machine Learning in Python. *JMLR*, 12, 2825-2830.
9. Paszke et al. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. *NeurIPS*.

---

## ğŸ“ ANEXOS

### Anexo A: InstalaciÃ³n Local

```bash
# Clonar repositorio
git clone https://github.com/Emma-Ok/Clasificaci-n-de-imagenes.git
cd Clasificaci-n-de-imagenes

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar aplicaciÃ³n
streamlit run app_streamlit_completa.py
```

### Anexo B: Uso de la AplicaciÃ³n

**Modo 1: TeorÃ­a de Filtros**
1. Seleccionar pestaÃ±a deseada (Resumen, Media, Mediana, etc.)
2. Leer explicaciÃ³n teÃ³rica con fÃ³rmulas matemÃ¡ticas
3. Ver ejemplos de aplicaciÃ³n

**Modo 2: Filtros Parte 1**
1. Subir imagen (JPG, PNG, JPEG)
2. Seleccionar filtro del menÃº desplegable
3. Ajustar parÃ¡metros con sliders
4. Ver resultado en tiempo real
5. Comparar con imagen original

**Modo 3: Entrenamiento**
1. Seleccionar modelo (CNN, SVM+HOG, SVM+LBP)
2. Ajustar hiperparÃ¡metros
3. Click en "Entrenar Modelo"
4. Esperar a que termine (ver progress bar)
5. Revisar mÃ©tricas y matriz de confusiÃ³n

**Modo 4: ClasificaciÃ³n**
1. Subir imagen a clasificar
2. Seleccionar modelo entrenado
3. Click en "Clasificar"
4. Ver predicciÃ³n con probabilidades
5. Revisar top-5 predicciones

### Anexo C: Estructura de Archivos

```
Tarea2Imagenes/
â”œâ”€â”€ app_streamlit_completa.py    # AplicaciÃ³n principal (1,580 lÃ­neas)
â”œâ”€â”€ requirements.txt              # Dependencias de Python
â”œâ”€â”€ packages.txt                  # Dependencias del sistema
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ config.toml              # ConfiguraciÃ³n de Streamlit
â”‚   â””â”€â”€ secrets.toml             # Secretos (vacÃ­o)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                   # 864 imÃ¡genes de entrenamiento
â”‚   â”‚   â”œâ”€â”€ class_0/ ... class_Z/
â”‚   â””â”€â”€ val/                     # 216 imÃ¡genes de validaciÃ³n
â”‚       â”œâ”€â”€ class_0/ ... class_Z/
â”œâ”€â”€ models/                      # Modelos entrenados (no en repo)
â”‚   â”œâ”€â”€ cnn_plate_classifier.pth
â”‚   â”œâ”€â”€ svm_hog_classifier.pkl
â”‚   â”œâ”€â”€ svm_lbp_classifier.pkl
â”‚   â”œâ”€â”€ classes.npy
â”‚   â””â”€â”€ descriptor_config.pkl
â”œâ”€â”€ TEORIA.md                    # DocumentaciÃ³n teÃ³rica
â”œâ”€â”€ INFORME.md                   # Este informe
â”œâ”€â”€ README.md                    # Instrucciones del proyecto
â””â”€â”€ .gitignore                   # Archivos ignorados por Git
```

### Anexo D: Comandos Git Ãštiles

```bash
# Ver estado
git status

# AÃ±adir cambios
git add .

# Commit
git commit -m "DescripciÃ³n del cambio"

# Push a GitHub
git push origin main

# Ver historial
git log --oneline

# Ver diferencias
git diff
```

---

## âœ… CHECKLIST DE COMPLETITUD

- [x] **PARTE 1 (30%): Filtros**
  - [x] 8 filtros implementados
  - [x] ParÃ¡metros ajustables
  - [x] VisualizaciÃ³n interactiva
  - [x] DocumentaciÃ³n teÃ³rica completa

- [x] **PARTE 2 (70%): ClasificaciÃ³n**
  - [x] Descriptores HOG implementados
  - [x] Descriptores LBP implementados
  - [x] SVM + HOG funcional
  - [x] SVM + LBP funcional
  - [x] CNN implementada y entrenable
  - [x] MÃ©tricas de evaluaciÃ³n completas
  - [x] Interfaz de clasificaciÃ³n

- [x] **Infraestructura**
  - [x] CÃ³digo versionado en Git
  - [x] Repositorio pÃºblico en GitHub
  - [x] AplicaciÃ³n desplegada en Streamlit Cloud
  - [x] DocumentaciÃ³n exhaustiva
  - [x] Informe tÃ©cnico completo

---

**Firma Digital:**  
Emmanuel Bustamante  
Universidad de Antioquia  
Noviembre 2025

---

*Este informe fue generado como parte de la Tarea 2 del curso de Procesamiento Digital de ImÃ¡genes. Todo el cÃ³digo es original y estÃ¡ disponible pÃºblicamente en GitHub bajo licencia MIT.*

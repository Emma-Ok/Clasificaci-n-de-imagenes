# ğŸ“Š INFORME TÃ‰CNICO - TAREA 2
## Procesamiento Digital de ImÃ¡genes: Filtros y ClasificaciÃ³n

---

### ğŸ“‹ INFORMACIÃ“N DEL PROYECTO

**Estudiante:** Emmanuel Bustamante  
**InstituciÃ³n:** Universidad de Antioquia  
**Curso:** Procesamiento Digital de ImÃ¡genes  
**Tarea:** Tarea 2 - Filtros y Descriptores de CaracterÃ­sticas  
**Fecha:** Noviembre 2025  
**Plataforma:** [Streamlit Cloud](https://clasificaci-n-de-imagenes-6je33ygv8xeoekkn2dl8qd.streamlit.app/)  
**Repositorio:** [GitHub - Emma-Ok/Clasificaci-n-de-imagenes](https://github.com/Emma-Ok/Clasificaci-n-de-imagenes)

---

## ğŸ“Œ RESUMEN EJECUTIVO

Este proyecto implementa una aplicaciÃ³n web interactiva para procesamiento de imÃ¡genes que abarca dos componentes principales:

1. **PARTE 1 (30%)**: Sistema de aplicaciÃ³n de filtros digitales con visualizaciÃ³n en tiempo real
2. **PARTE 2 (70%)**: Sistema completo de clasificaciÃ³n de caracteres alfanumÃ©ricos usando descriptores de caracterÃ­sticas y aprendizaje automÃ¡tico

La aplicaciÃ³n fue desarrollada en Python usando Streamlit como framework de interfaz grÃ¡fica, OpenCV para procesamiento de imÃ¡genes, scikit-learn para modelos tradicionales de ML, y PyTorch para redes neuronales convolucionales.

**CaracterÃ­sticas principales:**
- Interfaz web interactiva accesible desde cualquier navegador
- 8 filtros digitales implementados con parÃ¡metros ajustables
- 3 modelos de clasificaciÃ³n entrenables (SVM+HOG, SVM+LBP, CNN)
- Dataset de 1,080 imÃ¡genes (36 clases: 0-9, A-Z)
- MÃ©tricas de evaluaciÃ³n completas (accuracy, precision, recall, F1, matriz de confusiÃ³n)
- Despliegue en la nube con Streamlit Cloud

---

## ğŸ¯ OBJETIVOS

### Objetivos Generales
1. Implementar y analizar filtros de procesamiento de imÃ¡genes en el dominio espacial
2. Desarrollar un sistema de clasificaciÃ³n automÃ¡tica de caracteres usando descriptores de caracterÃ­sticas
3. Comparar el desempeÃ±o de mÃ©todos tradicionales (SVM) vs. aprendizaje profundo (CNN)

### Objetivos EspecÃ­ficos
- Programar 8 filtros digitales con parÃ¡metros configurables
- Extraer descriptores HOG y LBP de imÃ¡genes
- Entrenar clasificadores SVM con diferentes descriptores
- Implementar y entrenar una red neuronal convolucional
- Evaluar y comparar los modelos mediante mÃ©tricas estÃ¡ndar
- Crear una interfaz grÃ¡fica intuitiva para demostraciÃ³n

---

## ğŸ› ï¸ METODOLOGÃA

### 1. Arquitectura del Sistema

El proyecto estÃ¡ estructurado en cuatro mÃ³dulos principales:

```
app_streamlit_completa.py (1,580 lÃ­neas)
â”œâ”€â”€ ConfiguraciÃ³n global y constantes
â”œâ”€â”€ MÃ³dulo de filtros (PARTE 1 - 30%)
â”‚   â”œâ”€â”€ apply_filter(): Aplica filtros con parÃ¡metros
â”‚   â””â”€â”€ 8 filtros implementados
â”œâ”€â”€ MÃ³dulo de descriptores (PARTE 2 - 70%)
â”‚   â”œâ”€â”€ extract_hog_features(): ExtracciÃ³n HOG
â”‚   â””â”€â”€ extract_lbp_features(): ExtracciÃ³n LBP
â”œâ”€â”€ MÃ³dulo de modelos
â”‚   â”œâ”€â”€ PlateCNN: Arquitectura CNN (PyTorch)
â”‚   â”œâ”€â”€ train_cnn_model(): Entrenamiento CNN
â”‚   â”œâ”€â”€ train_svm_hog(): Entrenamiento SVM+HOG
â”‚   â””â”€â”€ train_svm_lbp(): Entrenamiento SVM+LBP
â””â”€â”€ Interfaz de usuario (Streamlit)
    â”œâ”€â”€ Modo TeorÃ­a de Filtros
    â”œâ”€â”€ Modo Filtros Parte 1
    â”œâ”€â”€ Modo Descriptores y ClasificaciÃ³n Parte 2
    â””â”€â”€ Modo Clasificar Imagen
```

### 2. Dataset

**Estructura:**
- **Total:** 1,080 imÃ¡genes
- **Clases:** 36 (dÃ­gitos 0-9 + letras A-Z)
- **ResoluciÃ³n:** 128Ã—64 pÃ­xeles
- **DivisiÃ³n:**
  - Entrenamiento: 864 imÃ¡genes (80%)
  - ValidaciÃ³n: 216 imÃ¡genes (20%)
- **Formato:** RGB, normalizado a escala de grises para descriptores

**OrganizaciÃ³n de carpetas:**
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class_0/ (24 imÃ¡genes)
â”‚   â”œâ”€â”€ class_1/ (24 imÃ¡genes)
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ class_Z/ (24 imÃ¡genes)
â””â”€â”€ val/
    â”œâ”€â”€ class_0/ (6 imÃ¡genes)
    â”œâ”€â”€ class_1/ (6 imÃ¡genes)
    â”œâ”€â”€ ...
    â””â”€â”€ class_Z/ (6 imÃ¡genes)
```

---

## ğŸ“ PARTE 1: FILTROS DE IMÃGENES (30%)

### 1.1 Filtros Implementados

Se implementaron 8 filtros digitales en el dominio espacial:

#### ğŸ”¹ 1. Filtro de Media
- **PropÃ³sito:** Suavizado mediante promedio aritmÃ©tico
- **FÃ³rmula:** `g(x,y) = (1/mn) Ã— Î£ Î£ f(x+i, y+j)`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7, 9Ã—9)
- **AplicaciÃ³n:** ReducciÃ³n de ruido gaussiano
- **Ventaja:** Simple y eficiente computacionalmente
- **Desventaja:** Difumina bordes

#### ğŸ”¹ 2. Filtro de Mediana
- **PropÃ³sito:** Suavizado mediante valor mediano
- **FÃ³rmula:** `g(x,y) = mediana{f(x+i, y+j)}`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7)
- **AplicaciÃ³n:** Excelente para ruido sal y pimienta
- **Ventaja:** Preserva bordes mejor que la media
- **Desventaja:** Mayor costo computacional

#### ğŸ”¹ 3. Filtro LogarÃ­tmico
- **PropÃ³sito:** CompresiÃ³n de rango dinÃ¡mico
- **FÃ³rmula:** `g(x,y) = c Ã— log(1 + f(x,y))`
- **ParÃ¡metro ajustable:** Factor de escala c (1-100)
- **AplicaciÃ³n:** Realce de detalles en zonas oscuras
- **Ventaja:** Mejora visualizaciÃ³n de imÃ¡genes HDR
- **Desventaja:** Puede sobreexponer zonas claras

#### ğŸ”¹ 4. Filtro Cuadro Normalizado
- **PropÃ³sito:** Suavizado uniforme con normalizaciÃ³n
- **ImplementaciÃ³n:** `cv2.boxFilter()` con `normalize=True`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7, 9Ã—9)
- **AplicaciÃ³n:** ReducciÃ³n de ruido con efecto de blur uniforme
- **Ventaja:** RÃ¡pido y predecible
- **Desventaja:** PÃ©rdida de detalles finos

#### ğŸ”¹ 5. Filtro Gaussiano
- **PropÃ³sito:** Suavizado ponderado gaussianamente
- **FÃ³rmula:** `G(x,y) = (1/2Ï€ÏƒÂ²) Ã— exp(-(xÂ²+yÂ²)/2ÏƒÂ²)`
- **ParÃ¡metros ajustables:** 
  - TamaÃ±o de kernel (3Ã—3, 5Ã—5, 7Ã—7, 9Ã—9)
  - Sigma Ïƒ (0.5 - 5.0)
- **AplicaciÃ³n:** Preprocesamiento para detecciÃ³n de bordes
- **Ventaja:** Suavizado natural, preserva mejor los bordes que la media
- **Desventaja:** MÃ¡s costoso que filtro de media

#### ğŸ”¹ 6. Filtro Laplaciano
- **PropÃ³sito:** DetecciÃ³n de bordes mediante segunda derivada
- **FÃ³rmula:** `âˆ‡Â²f = âˆ‚Â²f/âˆ‚xÂ² + âˆ‚Â²f/âˆ‚yÂ²`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (1, 3, 5)
- **AplicaciÃ³n:** Realce de bordes y detalles
- **Ventaja:** Detecta bordes en todas direcciones
- **Desventaja:** Muy sensible al ruido

#### ğŸ”¹ 7. Filtro Sobel
- **PropÃ³sito:** DetecciÃ³n de bordes mediante gradiente
- **FÃ³rmulas:**
  - Gx (horizontal): `[-1 0 1; -2 0 2; -1 0 1]`
  - Gy (vertical): `[-1 -2 -1; 0 0 0; 1 2 1]`
  - Magnitud: `G = âˆš(GxÂ² + GyÂ²)`
- **ParÃ¡metro ajustable:** TamaÃ±o de kernel (3, 5, 7)
- **AplicaciÃ³n:** DetecciÃ³n direccional de bordes
- **Ventaja:** Robustez al ruido, detecciÃ³n direccional
- **Desventaja:** Puede perderse informaciÃ³n de bordes dÃ©biles

#### ğŸ”¹ 8. Filtro Canny
- **PropÃ³sito:** DetecciÃ³n Ã³ptima de bordes multi-etapa
- **Etapas:**
  1. Suavizado gaussiano (reducciÃ³n de ruido)
  2. CÃ¡lculo de gradiente (Sobel)
  3. SupresiÃ³n no-mÃ¡xima (adelgazamiento)
  4. UmbralizaciÃ³n con histÃ©resis
- **ParÃ¡metros ajustables:**
  - Umbral inferior (50-200)
  - Umbral superior (100-300)
- **AplicaciÃ³n:** DetecciÃ³n precisa de contornos
- **Ventaja:** Mejor relaciÃ³n seÃ±al-ruido, bordes continuos
- **Desventaja:** Requiere ajuste cuidadoso de umbrales

### 1.2 ImplementaciÃ³n TÃ©cnica

```python
def apply_filter(image_np, filter_type, **kwargs):
    """
    Aplica filtro seleccionado con parÃ¡metros configurables
    
    Args:
        image_np: Imagen en escala de grises (numpy array)
        filter_type: Tipo de filtro ('Media', 'Mediana', etc.)
        **kwargs: ParÃ¡metros especÃ­ficos del filtro
    
    Returns:
        Imagen filtrada (numpy array)
    """
    if filter_type == "Media":
        ksize = kwargs.get('kernel_size', 5)
        return cv2.blur(image_np, (ksize, ksize))
    
    elif filter_type == "Mediana":
        ksize = kwargs.get('kernel_size', 5)
        return cv2.medianBlur(image_np, ksize)
    
    # ... [7 filtros mÃ¡s]
```

### 1.3 Interfaz de Usuario - Filtros

**CaracterÃ­sticas de la interfaz:**
- DiseÃ±o de dos columnas (imagen original | imagen filtrada)
- Selectores de filtro con menÃº desplegable
- Sliders para ajuste de parÃ¡metros en tiempo real
- VisualizaciÃ³n simultÃ¡nea de resultados
- InformaciÃ³n del filtro y parÃ¡metros aplicados

---

## ğŸ§  PARTE 2: DESCRIPTORES Y CLASIFICACIÃ“N (70%)

### 2.1 Descriptores de CaracterÃ­sticas

#### ğŸ”¸ HOG (Histogram of Oriented Gradients)

**Concepto:**  
Descriptor que captura la distribuciÃ³n de gradientes de intensidad en regiones locales de la imagen.

**ParÃ¡metros de extracciÃ³n:**
```python
hog_params = {
    'orientations': 9,           # Bins de orientaciÃ³n
    'pixels_per_cell': (8, 8),   # TamaÃ±o de celda
    'cells_per_block': (2, 2),   # Celdas por bloque
    'block_norm': 'L2-Hys',      # NormalizaciÃ³n L2-Hys
    'transform_sqrt': True,       # RaÃ­z cuadrada de valores
    'feature_vector': True        # Vector 1D de salida
}
```

**Proceso:**
1. ConversiÃ³n a escala de grises
2. CÃ¡lculo de gradientes (Sobel)
3. DivisiÃ³n en celdas de 8Ã—8 pÃ­xeles
4. CÃ¡lculo de histograma de 9 bins por celda
5. AgrupaciÃ³n en bloques de 2Ã—2 celdas
6. NormalizaciÃ³n L2-Hys por bloque
7. ConcatenaciÃ³n en vector de caracterÃ­sticas

**DimensiÃ³n del vector:** ~3,780 caracterÃ­sticas (128Ã—64 imagen)

**Ventajas:**
- Robusto a cambios de iluminaciÃ³n
- Invariante a pequeÃ±as deformaciones
- Captura informaciÃ³n de forma/estructura

**Desventajas:**
- Sensible a rotaciÃ³n
- No captura informaciÃ³n de textura fina

#### ğŸ”¸ LBP (Local Binary Patterns)

**Concepto:**  
Descriptor de textura que codifica la relaciÃ³n entre pÃ­xel central y vecinos.

**ParÃ¡metros de extracciÃ³n:**
```python
lbp_params = {
    'radius': 3,        # Radio de vecindad
    'n_points': 24,     # Puntos de muestreo (8 Ã— radius)
    'method': 'uniform' # Patrones uniformes
}
```

**Proceso:**
1. ConversiÃ³n a escala de grises
2. Para cada pÃ­xel (x,y):
   - Muestrear 24 vecinos en radio 3
   - Comparar con valor central
   - Generar cÃ³digo binario
   - Convertir a valor decimal
3. Calcular histograma de patrones
4. Normalizar histograma

**DimensiÃ³n del vector:** 26 caracterÃ­sticas (patrones uniformes)

**Ventajas:**
- Invariante a cambios monÃ³tonos de iluminaciÃ³n
- Muy eficiente computacionalmente
- Captura informaciÃ³n de textura local

**Desventajas:**
- Sensible a ruido
- Pierde informaciÃ³n de contraste

### 2.2 Modelos de ClasificaciÃ³n

Se implementaron 3 modelos diferentes para comparaciÃ³n:

#### ğŸ¤– Modelo 1: SVM + HOG

**Arquitectura:**
```python
Pipeline(
    StandardScaler(),              # NormalizaciÃ³n Z-score
    LinearSVC(                     # SVM lineal
        max_iter=5000,
        dual=True,
        random_state=42,
        class_weight='balanced'
    )
)
```

**CaracterÃ­sticas:**
- Input: Vector HOG de ~3,780 dimensiones
- Escalado: Media 0, desviaciÃ³n estÃ¡ndar 1
- Clasificador: SVM con kernel lineal
- Clases balanceadas: Pesos inversamente proporcionales

**Entrenamiento:**
- Tiempo estimado: 2-5 minutos
- Memoria requerida: ~500 MB
- Convergencia: 5,000 iteraciones mÃ¡ximas

#### ğŸ¤– Modelo 2: SVM + LBP

**Arquitectura:**
```python
Pipeline(
    StandardScaler(),              # NormalizaciÃ³n Z-score
    LinearSVC(                     # SVM lineal
        max_iter=5000,
        dual=True,
        random_state=42,
        class_weight='balanced'
    )
)
```

**CaracterÃ­sticas:**
- Input: Vector LBP de 26 dimensiones
- Escalado: Media 0, desviaciÃ³n estÃ¡ndar 1
- Clasificador: SVM con kernel lineal
- Clases balanceadas: Pesos inversamente proporcionales

**Entrenamiento:**
- Tiempo estimado: <1 minuto
- Memoria requerida: ~100 MB
- Convergencia: RÃ¡pida (pocas dimensiones)

#### ğŸ¤– Modelo 3: CNN (Convolutional Neural Network)

**Arquitectura detallada:**

```python
PlateCNN(
    # Bloque convolucional 1
    Conv2d(3 â†’ 32, kernel=3Ã—3, padding=1)
    BatchNorm2d(32)
    ReLU()
    MaxPool2d(2Ã—2)                  # 128Ã—64 â†’ 64Ã—32
    
    # Bloque convolucional 2
    Conv2d(32 â†’ 64, kernel=3Ã—3, padding=1)
    BatchNorm2d(64)
    ReLU()
    MaxPool2d(2Ã—2)                  # 64Ã—32 â†’ 32Ã—16
    
    # Bloque convolucional 3
    Conv2d(64 â†’ 128, kernel=3Ã—3, padding=1)
    BatchNorm2d(128)
    ReLU()
    MaxPool2d(2Ã—2)                  # 32Ã—16 â†’ 16Ã—8
    
    # Bloque convolucional 4
    Conv2d(128 â†’ 256, kernel=3Ã—3, padding=1)
    BatchNorm2d(256)
    ReLU()
    AdaptiveAvgPool2d(1Ã—1)          # 16Ã—8 â†’ 1Ã—1
    
    # Clasificador fully-connected
    Flatten()
    Dropout(0.4)
    Linear(256 â†’ 128)
    ReLU()
    Dropout(0.3)
    Linear(128 â†’ 36)                # 36 clases
)
```

**ParÃ¡metros totales:** ~75,000

**CaracterÃ­sticas:**
- Input: ImÃ¡genes RGB 128Ã—64Ã—3
- 4 bloques convolucionales con BatchNorm
- Global Average Pooling adaptativo
- 2 capas fully-connected
- Dropout para regularizaciÃ³n (40% y 30%)

**HiperparÃ¡metros de entrenamiento:**
```python
optimizer = Adam(
    lr=0.001,              # Learning rate
    weight_decay=1e-4      # RegularizaciÃ³n L2
)
loss = CrossEntropyLoss() # PÃ©rdida multi-clase
batch_size = 32
epochs = 20
```

**Proceso de entrenamiento:**
1. Carga de datos con DataLoader
2. AugmentaciÃ³n: normalizaciÃ³n RGB
3. Forward pass en batches
4. CÃ¡lculo de pÃ©rdida (Cross-Entropy)
5. Backpropagation con Adam
6. ValidaciÃ³n cada epoch
7. Early stopping si no mejora

**Tiempo estimado:** 10-15 minutos (CPU)  
**Memoria requerida:** ~2 GB

### 2.3 MÃ©tricas de EvaluaciÃ³n

Para cada modelo se calculan las siguientes mÃ©tricas:

#### ğŸ“Š MÃ©tricas Globales
- **Accuracy:** Porcentaje de predicciones correctas
  ```
  Accuracy = (TP + TN) / (TP + TN + FP + FN)
  ```

- **Precision (macro-avg):** Promedio de precisiÃ³n por clase
  ```
  Precision = TP / (TP + FP)
  ```

- **Recall (macro-avg):** Promedio de sensibilidad por clase
  ```
  Recall = TP / (TP + FN)
  ```

- **F1-Score (macro-avg):** Media armÃ³nica de precision y recall
  ```
  F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
  ```

#### ğŸ“Š Matriz de ConfusiÃ³n
- VisualizaciÃ³n 36Ã—36 de predicciones vs. verdad
- Diagonal: Predicciones correctas
- Fuera de diagonal: Confusiones entre clases

#### ğŸ“Š Reporte por Clase
- Precision, Recall, F1-Score para cada una de las 36 clases
- IdentificaciÃ³n de clases problemÃ¡ticas

---

## ğŸ’» IMPLEMENTACIÃ“N TÃ‰CNICA

### 3.1 Stack TecnolÃ³gico

**Lenguajes y Frameworks:**
- Python 3.12
- Streamlit 1.39.0 (interfaz web)
- OpenCV 4.10.0 (procesamiento de imÃ¡genes)
- scikit-learn 1.5.2 (SVM, mÃ©tricas)
- PyTorch 2.4.1 (redes neuronales)
- NumPy 1.26.4 (operaciones numÃ©ricas)
- Pandas 2.2.3 (manejo de datos)
- Matplotlib 3.9.2 (visualizaciÃ³n)

**Infraestructura:**
- Git/GitHub (control de versiones)
- Streamlit Cloud (deployment)
- Python venv (gestiÃ³n de dependencias)

### 3.2 Estructura del CÃ³digo

**OrganizaciÃ³n modular:**
```python
# 1. ConfiguraciÃ³n y constantes (lÃ­neas 1-70)
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
MODEL_DIR = Path('models')

# 2. Arquitectura CNN (lÃ­neas 71-117)
class PlateCNN(nn.Module):
    # ... definiciÃ³n de capas

# 3. Funciones de filtros (lÃ­neas 118-166)
def apply_filter(image_np, filter_type, **kwargs):
    # ... implementaciÃ³n de 8 filtros

# 4. ExtracciÃ³n de descriptores (lÃ­neas 167-244)
def extract_hog_features(image_gray, hog_params):
def extract_lbp_features(image_gray, radius, n_points):

# 5. Entrenamiento de modelos (lÃ­neas 245-380)
def train_cnn_model(data_root, epochs, lr, batch_size, weight_decay):
def train_svm_hog(data_root, hog_params):
def train_svm_lbp(data_root, radius, n_points):

# 6. TeorÃ­a de filtros (lÃ­neas 381-1127)
# 9 tabs con explicaciones matemÃ¡ticas completas

# 7. Interfaz principal (lÃ­neas 1128-1580)
def main():
    # Modo TeorÃ­a, Filtros, Entrenamiento, ClasificaciÃ³n
```

### 3.3 Optimizaciones Implementadas

#### âš¡ Rendimiento
- Progress bars con ETA cada 10 imÃ¡genes durante entrenamiento
- Carga lazy de modelos (solo cuando se necesitan)
- Cache de descriptores para evitar recÃ¡lculo
- Batch processing en CNN para eficiencia

#### ğŸ”’ Robustez
- ValidaciÃ³n de existencia de archivos
- Manejo de excepciones en carga de modelos
- VerificaciÃ³n de dimensiones de entrada
- NormalizaciÃ³n automÃ¡tica de imÃ¡genes

#### ğŸ¨ Interfaz de Usuario
- DiseÃ±o responsive con columnas
- Feedback visual con spinners y progress bars
- Mensajes informativos con st.info/success/warning
- VisualizaciÃ³n de resultados en tablas y grÃ¡ficos

---

## ğŸ“ˆ RESULTADOS

### 4.1 DesempeÃ±o de Modelos

Los resultados esperados (basados en arquitectura y dataset):

| Modelo | Accuracy Esperada | Tiempo Entrenamiento | TamaÃ±o Modelo |
|--------|-------------------|---------------------|---------------|
| **SVM + HOG** | 85-92% | 2-5 min | ~15 MB |
| **SVM + LBP** | 70-80% | <1 min | ~1 MB |
| **CNN** | 90-96% | 10-15 min | ~300 KB |

**AnÃ¡lisis comparativo:**

**SVM + HOG:**
- âœ… Buen balance entre precisiÃ³n y velocidad
- âœ… Interpetable (vectores de soporte)
- âœ… Funciona bien con datos limitados
- âŒ Requiere ingenierÃ­a de caracterÃ­sticas manual
- âŒ Escalado lineal con tamaÃ±o de dataset

**SVM + LBP:**
- âœ… Muy rÃ¡pido (26 caracterÃ­sticas)
- âœ… Eficiente en memoria
- âœ… Bueno para texturas
- âŒ Menor precisiÃ³n que HOG
- âŒ Pierde informaciÃ³n espacial global

**CNN:**
- âœ… Mayor precisiÃ³n potencial
- âœ… Aprendizaje automÃ¡tico de caracterÃ­sticas
- âœ… Escalable a datasets grandes
- âŒ Requiere mÃ¡s datos de entrenamiento
- âŒ Mayor tiempo de entrenamiento
- âŒ Menos interpretable

### 4.2 Despliegue en ProducciÃ³n

**URL de la aplicaciÃ³n:**  
https://clasificaci-n-de-imagenes-6je33ygv8xeoekkn2dl8qd.streamlit.app/

**ConfiguraciÃ³n de despliegue:**

**packages.txt** (dependencias del sistema):
```bash
libgl1-mesa-glx    # OpenGL para OpenCV
libglib2.0-0       # GLib para procesamiento
```

**requirements.txt** (dependencias de Python):
```
opencv-python-headless==4.10.0.84
numpy==1.26.4
matplotlib==3.9.2
scikit-image==0.24.0
Pillow==10.4.0
scikit-learn==1.5.2
torch==2.4.1
torchvision==0.19.1
pandas==2.2.3
seaborn==0.13.2
streamlit==1.39.0
tqdm==4.66.5
```

**Problemas resueltos durante deployment:**
1. âŒ Python 3.13 incompatible con PyTorch â†’ âœ… Forzar Python 3.12
2. âŒ opencv-python requiere libGL â†’ âœ… Usar opencv-python-headless
3. âŒ width='stretch' deprecado â†’ âœ… use_column_width=True
4. âŒ uv instalando versiones incorrectas â†’ âœ… Remover runtime.txt

---

## ğŸ“ CONCLUSIONES

### 5.1 Logros del Proyecto

1. **ImplementaciÃ³n Completa:**
   - âœ… 8 filtros digitales funcionales con parÃ¡metros ajustables
   - âœ… 2 descriptores de caracterÃ­sticas (HOG, LBP) implementados
   - âœ… 3 modelos de clasificaciÃ³n entrenables (SVMÃ—2, CNN)
   - âœ… Interfaz web interactiva y responsive
   - âœ… Despliegue exitoso en Streamlit Cloud

2. **Aprendizajes TÃ©cnicos:**
   - ComprensiÃ³n profunda de filtros en dominio espacial
   - Dominio de descriptores de caracterÃ­sticas tradicionales
   - Experiencia prÃ¡ctica con SVM y redes neuronales
   - Desarrollo de aplicaciones web con Streamlit
   - GestiÃ³n de deployment y dependencias en la nube

3. **Resultados AcadÃ©micos:**
   - DocumentaciÃ³n exhaustiva con fundamentos matemÃ¡ticos
   - ImplementaciÃ³n modular y bien estructurada
   - CÃ³digo reproducible y versionado en Git
   - AplicaciÃ³n funcional accesible pÃºblicamente

### 5.2 ComparaciÃ³n de Enfoques

**MÃ©todos Tradicionales (SVM + Descriptores):**
- Requieren ingenierÃ­a de caracterÃ­sticas manual
- Mayor interpretabilidad
- Funcionan bien con datasets pequeÃ±os
- Entrenamiento rÃ¡pido
- Buen desempeÃ±o en problemas bien definidos

**Deep Learning (CNN):**
- Aprendizaje automÃ¡tico de caracterÃ­sticas
- Mayor capacidad de generalizaciÃ³n
- Requieren mÃ¡s datos y cÃ³mputo
- Mejor desempeÃ±o en problemas complejos
- Menos interpretables pero mÃ¡s flexibles

### 5.3 Limitaciones y Trabajo Futuro

**Limitaciones actuales:**
- Dataset limitado (1,080 imÃ¡genes)
- Entrenamiento solo en CPU (no GPU en Streamlit Cloud)
- Sin data augmentation extensiva
- Modelos no optimizados para producciÃ³n (sin cuantizaciÃ³n)

**Mejoras propuestas:**
1. **Dataset:**
   - Aumentar a 10,000+ imÃ¡genes
   - Data augmentation (rotaciÃ³n, escalado, ruido)
   - Incluir imÃ¡genes de diferentes fuentes

2. **Modelos:**
   - Transfer learning (ResNet, EfficientNet pre-entrenados)
   - Ensemble de modelos (voting)
   - OptimizaciÃ³n de hiperparÃ¡metros (Grid Search, Bayesian Opt)
   - CuantizaciÃ³n post-entrenamiento para inferencia rÃ¡pida

3. **AplicaciÃ³n:**
   - API REST para integraciÃ³n
   - Modo batch para procesamiento masivo
   - CachÃ© de modelos para reducir latencia
   - Soporte para GPU en deployment

4. **Filtros:**
   - MÃ¡s filtros (bilateral, anisotropic diffusion)
   - Filtros en dominio de frecuencia (FFT, DCT)
   - Procesamiento en color (espacios HSV, LAB)

### 5.4 ReflexiÃ³n Personal

Este proyecto demostrÃ³ la importancia de entender tanto los fundamentos teÃ³ricos (filtros digitales, descriptores de caracterÃ­sticas) como las herramientas modernas (deep learning, cloud deployment). La implementaciÃ³n prÃ¡ctica revelÃ³ que:

- **No existe un modelo perfecto:** Cada enfoque tiene trade-offs
- **La ingenierÃ­a de datos es crucial:** Preprocesamiento y extracciÃ³n de caracterÃ­sticas impactan significativamente
- **La visualizaciÃ³n es poderosa:** Una interfaz intuitiva facilita la comprensiÃ³n
- **El deployment tiene desafÃ­os Ãºnicos:** Compatibilidad de dependencias, limitaciones de recursos

La experiencia de llevar un proyecto desde la teorÃ­a hasta una aplicaciÃ³n web funcional proporciona una visiÃ³n integral del ciclo de vida del desarrollo de software en machine learning.

---

## ğŸ“š REFERENCIAS

### TeorÃ­a de Filtros
1. Gonzalez, R. C., & Woods, R. E. (2018). *Digital Image Processing* (4th ed.). Pearson.
2. Pratt, W. K. (2007). *Digital Image Processing* (4th ed.). Wiley-Interscience.

### Descriptores de CaracterÃ­sticas
3. Dalal, N., & Triggs, B. (2005). Histograms of oriented gradients for human detection. *CVPR*.
4. Ojala, T., PietikÃ¤inen, M., & MÃ¤enpÃ¤Ã¤, T. (2002). Multiresolution gray-scale and rotation invariant texture classification with local binary patterns. *TPAMI*, 24(7), 971-987.

### Machine Learning
5. Cortes, C., & Vapnik, V. (1995). Support-vector networks. *Machine Learning*, 20(3), 273-297.
6. LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. *Nature*, 521(7553), 436-444.

### Herramientas
7. Bradski, G. (2000). The OpenCV Library. *Dr. Dobb's Journal*.
8. Pedregosa et al. (2011). Scikit-learn: Machine Learning in Python. *JMLR*, 12, 2825-2830.
9. Paszke et al. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. *NeurIPS*.

---

## ğŸ“ ANEXOS

### Anexo A: InstalaciÃ³n Local

```bash
# Clonar repositorio
git clone https://github.com/Emma-Ok/Clasificaci-n-de-imagenes.git
cd Clasificaci-n-de-imagenes

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar aplicaciÃ³n
streamlit run app_streamlit_completa.py
```

### Anexo B: Uso de la AplicaciÃ³n

**Modo 1: TeorÃ­a de Filtros**
1. Seleccionar pestaÃ±a deseada (Resumen, Media, Mediana, etc.)
2. Leer explicaciÃ³n teÃ³rica con fÃ³rmulas matemÃ¡ticas
3. Ver ejemplos de aplicaciÃ³n

**Modo 2: Filtros Parte 1**
1. Subir imagen (JPG, PNG, JPEG)
2. Seleccionar filtro del menÃº desplegable
3. Ajustar parÃ¡metros con sliders
4. Ver resultado en tiempo real
5. Comparar con imagen original

**Modo 3: Entrenamiento**
1. Seleccionar modelo (CNN, SVM+HOG, SVM+LBP)
2. Ajustar hiperparÃ¡metros
3. Click en "Entrenar Modelo"
4. Esperar a que termine (ver progress bar)
5. Revisar mÃ©tricas y matriz de confusiÃ³n

**Modo 4: ClasificaciÃ³n**
1. Subir imagen a clasificar
2. Seleccionar modelo entrenado
3. Click en "Clasificar"
4. Ver predicciÃ³n con probabilidades
5. Revisar top-5 predicciones

### Anexo C: Estructura de Archivos

```
Tarea2Imagenes/
â”œâ”€â”€ app_streamlit_completa.py    # AplicaciÃ³n principal (1,580 lÃ­neas)
â”œâ”€â”€ requirements.txt              # Dependencias de Python
â”œâ”€â”€ packages.txt                  # Dependencias del sistema
â”œâ”€â”€ .streamlit/
â”‚   â”œâ”€â”€ config.toml              # ConfiguraciÃ³n de Streamlit
â”‚   â””â”€â”€ secrets.toml             # Secretos (vacÃ­o)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                   # 864 imÃ¡genes de entrenamiento
â”‚   â”‚   â”œâ”€â”€ class_0/ ... class_Z/
â”‚   â””â”€â”€ val/                     # 216 imÃ¡genes de validaciÃ³n
â”‚       â”œâ”€â”€ class_0/ ... class_Z/
â”œâ”€â”€ models/                      # Modelos entrenados (no en repo)
â”‚   â”œâ”€â”€ cnn_plate_classifier.pth
â”‚   â”œâ”€â”€ svm_hog_classifier.pkl
â”‚   â”œâ”€â”€ svm_lbp_classifier.pkl
â”‚   â”œâ”€â”€ classes.npy
â”‚   â””â”€â”€ descriptor_config.pkl
â”œâ”€â”€ TEORIA.md                    # DocumentaciÃ³n teÃ³rica
â”œâ”€â”€ INFORME.md                   # Este informe
â”œâ”€â”€ README.md                    # Instrucciones del proyecto
â””â”€â”€ .gitignore                   # Archivos ignorados por Git
```

### Anexo D: Comandos Git Ãštiles

```bash
# Ver estado
git status

# AÃ±adir cambios
git add .

# Commit
git commit -m "DescripciÃ³n del cambio"

# Push a GitHub
git push origin main

# Ver historial
git log --oneline

# Ver diferencias
git diff
```

---

## âœ… CHECKLIST DE COMPLETITUD

- [x] **PARTE 1 (30%): Filtros**
  - [x] 8 filtros implementados
  - [x] ParÃ¡metros ajustables
  - [x] VisualizaciÃ³n interactiva
  - [x] DocumentaciÃ³n teÃ³rica completa

- [x] **PARTE 2 (70%): ClasificaciÃ³n**
  - [x] Descriptores HOG implementados
  - [x] Descriptores LBP implementados
  - [x] SVM + HOG funcional
  - [x] SVM + LBP funcional
  - [x] CNN implementada y entrenable
  - [x] MÃ©tricas de evaluaciÃ³n completas
  - [x] Interfaz de clasificaciÃ³n

- [x] **Infraestructura**
  - [x] CÃ³digo versionado en Git
  - [x] Repositorio pÃºblico en GitHub
  - [x] AplicaciÃ³n desplegada en Streamlit Cloud
  - [x] DocumentaciÃ³n exhaustiva
  - [x] Informe tÃ©cnico completo

---

**Firma Digital:**  
Emmanuel Bustamante  
Universidad de Antioquia  
Noviembre 2025

---

*Este informe fue generado como parte de la Tarea 2 del curso de Procesamiento Digital de ImÃ¡genes. Todo el cÃ³digo es original y estÃ¡ disponible pÃºblicamente en GitHub bajo licencia MIT.*
